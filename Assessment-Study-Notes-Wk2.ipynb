{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment Study Notes Wk2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Probability Distributions\n",
    "* *DONE: Complete Assignment & Review Solns - 3/28*\n",
    "* **TODO: Review distributions & how to draw from/plot - 3/29**\n",
    "    * How to use stats.expon()?? with certain lambda\n",
    "\n",
    "### 2. Binomial Tests\n",
    "* **DONE: Complete Assignment & Review Solns - 3/28**\n",
    "\n",
    "### 3. Sampling Distributions\n",
    "* **DONE: Complete Assignment & Review Solns - 3/28**\n",
    "\n",
    "### 4. Law of Large Numbers\n",
    "* **TODO: Complete Assignment & Review Solns - 3/28**\n",
    "\n",
    "### 5. Central Limit Theorem\n",
    "* **TODO: Complete Assignment & Review Solns - 3/28**\n",
    "\n",
    "### 6. Maximum Likelihood Estimation\n",
    "* **TODO: Complete Assignment & Review Solns - 3/29**\n",
    "\n",
    "### 7. Hypothesis Testing\n",
    "* **TODO: Complete Assignment & Review Solns - 3/29**\n",
    "\n",
    "### 8. Power Calculation\n",
    "* **TODO: Complete Assignment & Review Solns - 3/29**\n",
    "\n",
    "### 9. Bayesian Inference\n",
    "* *DONE: Complete Assignment & Review Solns - 3/28*\n",
    "* **TODO: Extra Credit - 3/29**\n",
    "\n",
    "### 10. Bayesian Testing\n",
    "* **TODO: Complete Assignment & Review Solns - 3/29**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Probability Distributions \n",
    "* Bernoulli \n",
    "* Binomial\n",
    "* Hypergeometric\n",
    "* Poisson\n",
    "* Uniform\n",
    "* Normal\n",
    "* Exponential\n",
    "* Gamma\n",
    "* Geometric\n",
    "* Beta\n",
    "\n",
    "### Summary Table\n",
    "| Distribution | Continuous/Discrete| Description | Parameters | Scipy |\n",
    "| --- | --- | --- | --- | -- |\n",
    "| Bernoulli | Discrete | single coin flip | $p$ is probability of success (heads = 1) | stats.bernoulli(p) |\n",
    "| Binomial | Discrete | flipping coin some number of times | $n$ is number of flips, $p$ is probability of success (heads = 1) | stats.binom(n, p) |\n",
    "| Hypergeometric | Discrete | deck of $M$ cards of two types (say $M-n$ red cards and $n$ blue cards) | $M$ is total number (cards), $n$ is total number of certain thing (blue cards only), $N$ is amount drawn| stats.hypergeom(M, n, N) |\n",
    "| Poisson | Discrete | events happen at a fixed **rate or frequency** | lambda | stats.poisson(mu) |\n",
    "| Uniform | Continuous (or Discrete) | fair die rolls | $b - a$ = num outcomes | stats.uniform(a, b - a) |\n",
    "| Normal | Continuous | bell shape, CTL | mean (mu), variance (sigma) | stats.norm(mu, sigma) |\n",
    "| Exponential | Continuous | related to Poisson, amount of time until 1st event | $lambda$ is rate event occurs | stats.expon(loc=lambda) |\n",
    "| Gamma | Continuous | related to Exponential, amount of time until k events | $k$ is num events, $theta$ is rate events occur |  |\n",
    "| Geometric |  |  |  |  |\n",
    "| Beta |  |  |  |  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scipy.stats._distn_infrastructure.rv_frozen at 0x1a1ff68610>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<scipy.stats._distn_infrastructure.rv_frozen at 0x1a1ff685d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<scipy.stats._distn_infrastructure.rv_frozen at 0x1a1f8ad550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<scipy.stats._distn_infrastructure.rv_frozen at 0x10d184d10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<scipy.stats._distn_infrastructure.rv_frozen at 0x1a1ff68e10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.binom(n=1, p=0.5)\n",
    "stats.bernoulli(p=0.5)\n",
    "stats.uniform(loc=0, scale=1)\n",
    "stats.poisson(mu=1) \n",
    "stats.expon(loc=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Binomial Tests\n",
    "1. State the null and alternate hypothesis.\n",
    "* State the distribution of the count under the null hypothesis (which, in every scenario, is a binomial distribution).\n",
    "* Plot the null binomial distribution, and shade the region to the right of the count you actually observed.\n",
    "* Calculate the p-value associated with the stated null and alternate hypothesis.\n",
    "Decide whether to reject the null hypothesis.\n",
    "\n",
    "Example:\n",
    "1. H0: p = 0.5, Ha: p > 0.5 \n",
    "* p-value: Probability of observing equal or rarer event\n",
    "    * P(Binom(n = _, p = 0.5) **>=** \"successes\") \n",
    "* If p-value < alpha (threshold usually 0.05), reject H0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sampling Distributions\n",
    "```python\n",
    "def bootstrap_sample_medians(data, n_bootstrap_samples=10**4):\n",
    "    bootstrap_sample_medians = []\n",
    "    for i in range(n_bootstrap_samples):\n",
    "        bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        bootstrap_sample_medians.append(np.median(bootstrap_sample))\n",
    "    return bootstrap_sample_medians\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Law of Large Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Central Limit Theorem\n",
    "#### Confidence Interval\n",
    "For population mean mu when n >= 30:\n",
    "```\n",
    "x_bar +- Factor*(sigma/sqrt(n)), where x_bar is sample mean, \n",
    "sigma is population std dev\n",
    "--> x_bar +- Factor*(s/sqrt(n)), where s is sample std dev\n",
    "```\n",
    "```python\n",
    "# To get Factor (1.96 for 95% CI)\n",
    "conf = 0.95\n",
    "stats.norm.ppf((1 + conf) / 2.) # --> 1.96\n",
    "```\n",
    "\n",
    "For population mean mu when n < 30:\n",
    "```\n",
    "x_bar +- t-dist(alpha/2, n-1)*(s/sqrt(n)), t-dist instead of normal\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Maximum Likelihood Estimation\n",
    "#### MLE for theta is value that maximizes likelihood function p(x, theta)\n",
    "* theta_ML = argmax(p(x, theta)) = argmax(ln(p(x, theta)))\n",
    " * ln(p(x, theta)) is log-likelihood function\n",
    "\n",
    "\n",
    "1. Assume underlying distribution (Poisson, Bernoulli, Binomial, Normal)\n",
    "* Define likelihood function\n",
    "* Choose parameter set that maximizes likelihood function\n",
    "\n",
    "```python\n",
    "def coin_log_likelihood(p, flips):\n",
    "\"\"\"Return the log-likelihood of a parameter p given a sequence of coin flips.\n",
    "\"\"\"\n",
    "    binom = stats.binom(p=p, n=1)\n",
    "    likelihoods = [binom.pmf(datum) for datum in flips]\n",
    "    return np.sum(np.log(likelihoods))\n",
    "\n",
    "# Reference from class for normal dist\n",
    "def log_likelihood_normal_two_parameters(mu, sigma_sq, data):\n",
    "    normal = scs.norm(mu, np.sqrt(sigma_sq))\n",
    "    likelihoods = [normal.pdf(datum) for datum in data]\n",
    "    return np.sum(np.log(likelihoods))\n",
    "\n",
    "# Poisson when data is counts of i events\n",
    "def poisson_likelihood(lam, data):\n",
    "    log_lik = np.sum(count * np.log(stats.poisson(lam).pmf(k)) for k, count in enumerate(data))\n",
    "    return log_lik\n",
    "\n",
    "lambs = np.linspace(0.1, 12, 250)\n",
    "log_lik_poisson = [poisson_likelihood(lamb, alpha_particle_counts) for lamb in lambs]\n",
    "\n",
    "max_likelihood_idx = np.argmax(log_lik_poisson) # likelihoods\n",
    "max_likelihood_estimate = lams[max_likelihood_idx] \n",
    "```\n",
    "\n",
    "#### *log likelihood (negative num) closer to zero indicates max likelihood estimate*\n",
    "```python\n",
    "def maximum_coin_likelihood(data: np.array) -> float:\n",
    "    ps = np.linspace(0, 1, num=100)\n",
    "    likelihoods = [coin_log_likelihood(p=p, flips=data) for p in ps]\n",
    "    max_likelihood_idx = np.argmax(likelihoods)\n",
    "    return ps[max_likelihood_idx]\n",
    "```\n",
    "#### Law of small numbers: Binomial distribution with a very large $N$ and a very small $p$ are very well approximated by Poisson distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hypothesis Testing\n",
    "#### t-test\n",
    "Welch's t-test, unlike Student's t-test, does NOT assume the two populations from which the samples are drawn have the same variance.\n",
    "```python\n",
    "scipy.stats.ttest_ind(a, b, equal_var=False) # Welch's t-test\n",
    "```\n",
    "#### z-test\n",
    "##### Two Sample Approximate Test of Population Proportions\n",
    "H_0: p_M <= p_N --> p_M = p_N = p (to make maximally difficult to reject)\n",
    "mean = 0\n",
    "```python\n",
    "shared_sample_freq = (p_M + p_N) / (n_M + n_N) \n",
    "shared_sample_variance = (n_M + n_N) * (shared_sample_freq * (1 - shared_sample_freq)) / (n_M * n_N)\n",
    "\n",
    "difference_in_proportions = stats.norm(0, np.sqrt(shared_sample_variance))\n",
    "\n",
    "difference_in_sample_proportions = p_M/n_M - p_N/n_N\n",
    "p_value = 1 - difference_in_proportions.cdf(difference_in_sample_proportions)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Power Calculation\n",
    "### Null Hypothesis Significance Testing Procedure\n",
    "1. State a scientific yes/no question\n",
    "* Take a skeptical stance: state a null hypothesis\n",
    "* State the opposite of your null hypothesis: the alternative hypothesis\n",
    "* Create a probabilistic model of the situation when the null is true\n",
    "* Determine how surprised you need to be to reject the null: determine a rejection level alpha\n",
    "* Collect your data\n",
    "* Calculate the conditional probability of finding a result equally or more extreme than you actually observed, assuming the null is true: this is your p-value\n",
    "* Compare the p-value to your stated rejection threshold, reject the null hypothesis if the p-value is smaller than your rejection level alpha\n",
    "> The **p-value** is the conditional probability of observing a result equally or more extreme than we actually observed, assuming the null hypothesis is true.\n",
    "\n",
    "##### P(Observe result equally or more extreme than actual | H_0)\n",
    "\n",
    "> The rejection level alpha is the **false positive rate under the null**.  I.e., if the null hypothesis is true, it is the probability we would collect data that falsely rejects the null hypothesis.\n",
    "\n",
    "x| Reject H0            | Fail to reject H0\n",
    "-------------|----------------------|------------------\n",
    "**H_0 false**| Correct (1 - beta)   | Type II error (beta)\n",
    "**H_0 true** | Type I error (alpha) | Correct (1 - alpha)\n",
    "\n",
    "#### Computing Power\n",
    "```python\n",
    "def compute_power(n, sigma, alpha, mu0, mua):\n",
    "    standard_error = sigma / n**0.5\n",
    "    h0 = scs.norm(mu0, standard_error)\n",
    "    ha = scs.norm(mua, standard_error)\n",
    "    critical_value = h0.ppf(1 - alpha)\n",
    "    power = 1 - ha.cdf(critical_value)\n",
    "    return power\n",
    "```\n",
    "#### Determining Sample Size Needed for Power\n",
    "``` python\n",
    "def sample_size_needed_for_power(alpha, power, mu0, mua, sigma):\n",
    "    standard_normal = scs.norm(0, 1)\n",
    "    beta = 1 - power\n",
    "    numerator = sigma * (standard_normal.ppf(1 - alpha) - standard_normal.ppf(beta))\n",
    "    denominator = mua - mu0\n",
    "    return math.ceil((numerator / denominator) ** 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Bayesian Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-4d66ebe7f474>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-4d66ebe7f474>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    result =\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "def roll_the_dice(n_simulations = 1000):\n",
    "    '''Two unbiased, six sided, dice are thrown one time and the sum of the\n",
    "    faces is observed (so if you rolled a 3 and a 1, the sum is 4). A\n",
    "    simulation estimates probability that the total score is an even number\n",
    "    or a number greater than 7.  This is an estimated probability, based on\n",
    "    rolling the two dice n_simulations times.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_simulations: float\n",
    "        Number of rolls of the dice\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    '''\n",
    "    binom = stats.binom(n_simulations, 1/6)\n",
    "    result = \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "def calculate_t_test(sample1, sample2, type_I_error_rate):\n",
    "    '''Evaluates whether the two samples come from a population with the same\n",
    "    population mean.  Returns a tuple containing the p-value for\n",
    "    the pair of samples and True or False depending if the p-value is\n",
    "    considered significant at the provided Type I Error Rate (i.e. false\n",
    "    positive rate, i.e. alpha).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sample1, sample2: NumPy array, NumPy array\n",
    "    type_I_error_rate: float\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float, boolean\n",
    "    '''\n",
    "    _, p_val = stats.ttest_ind(sample1, sample2, equal_var=False)\n",
    "    if p_val < type_I_error_rate:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4-year, Public</td>\n",
       "      <td>11478.913765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4-year, primarily associate's, Public</td>\n",
       "      <td>6889.366197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4-year, Private for-profit</td>\n",
       "      <td>3504.501859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4-year, Private not-for-profit</td>\n",
       "      <td>2399.885696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4-year, primarily associate's, Private not-for...</td>\n",
       "      <td>1129.413793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4-year, primarily associate's, Private for-profit</td>\n",
       "      <td>934.380597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Type          Size\n",
       "2                                     4-year, Public  11478.913765\n",
       "5              4-year, primarily associate's, Public   6889.366197\n",
       "0                         4-year, Private for-profit   3504.501859\n",
       "1                     4-year, Private not-for-profit   2399.885696\n",
       "4  4-year, primarily associate's, Private not-for...   1129.413793\n",
       "3  4-year, primarily associate's, Private for-profit    934.380597"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('universities.csv')\n",
    "grouped = df.groupby(['Type']).mean().reset_index()\n",
    "grouped.sort_values('Size', ascending=False)\n",
    "\n",
    "def pandas_query(df):\n",
    "    '''Returns a DataFrame containing the average size of each university\n",
    "    type ordered by average size in ascending order.\n",
    "\n",
    "    Function assumes the input DataFrame contains these columns:\n",
    "        name, address, Website, Type, Size\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: Pandas DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame\n",
    "    '''\n",
    "    df.groupby(['Type']).mean().reset_index()\n",
    "    \n",
    "    \n",
    "pandas_query(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['A T Still University of Health Sciences',\n",
       "        'Abilene Christian University',\n",
       "        'Abraham Baldwin Agricultural College', ...,\n",
       "        'York College Pennsylvania', 'Youngstown State University',\n",
       "        'Zion Bible College'], dtype=object),\n",
       " array([['800 W Jefferson, Kirksville, Missouri 63501', 'WWW.ATSU.EDU',\n",
       "         '4-year, Private not-for-profit', 3480.0],\n",
       "        ['1600 Campus Court, Abilene, Texas 79699', 'www.acu.edu',\n",
       "         '4-year, Private not-for-profit', 4669.0],\n",
       "        ['2802 Moore Hwy, Tifton, Georgia 31793-2601', 'www.abac.edu',\n",
       "         \"4-year, primarily associate's, Public\", 3600.0],\n",
       "        ...,\n",
       "        ['Country Club Rd, York, Pennsylvania 17403-3651', 'www.ycp.edu',\n",
       "         '4-year, Private not-for-profit', 5627.0],\n",
       "        ['One University Plaza, Youngstown, Ohio 44555-0001',\n",
       "         'www.ysu.edu', '4-year, Public', 13704.0],\n",
       "        ['320 South Main Street, Haverhill, Massachusetts 01835',\n",
       "         'www.zbc.edu', '4-year, Private not-for-profit', 247.0]],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('universities.csv')\n",
    "y_column = 'name'\n",
    "array1 = np.array(df[y_column])\n",
    "df_copy = df.drop(y_column, axis=1)\n",
    "array2 = df_copy.to_numpy()\n",
    "array1, array2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def size_of_multiply(A, B):\n",
    "    '''If matrices A (dimensions m x n) and B (dimensions p x q) can be\n",
    "    multiplied (AB), returns the shape of the result of multiplying them.\n",
    "    Function DOES NOT perform the multiplication. If A and B cannot be\n",
    "    multiplied, returns None. (Use the shape function.)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A, B: NumPy array, NumPy array\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (int, int) or None  \n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7850091519999999"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "binom = stats.binom(10, 0.6)\n",
    "1 - binom.pmf(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.35"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sample = [10, 25, 12, 35, 14, 18, 16, 15, 22, 10, 9, 11, 49, 20, 15, 9, 18, 19, 20, 20]\n",
    "np.mean(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.9275"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sample = [10, 25, 12, 35, 14, 18, 16, 15, 22, 10, 9, 11, 49, 20, 15, 9, 18, 19, 20, 20]\n",
    "np.var(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7850091519999999"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a) 18.35\n",
    "\n",
    "import numpy as np\n",
    "sample = [10, 25, 12, 35, 14, 18, 16, 15, 22, 10, 9, 11, 49, 20, 15, 9, 18, 19, 20, 20]\n",
    "np.mean(sample)\n",
    "\n",
    "b) 86.9275\n",
    "\n",
    "import numpy as np\n",
    "sample = [10, 25, 12, 35, 14, 18, 16, 15, 22, 10, 9, 11, 49, 20, 15, 9, 18, 19, 20, 20]\n",
    "np.var(sample)a) 18.35\n",
    "\n",
    "import numpy as np\n",
    "sample = [10, 25, 12, 35, 14, 18, 16, 15, 22, 10, 9, 11, 49, 20, 15, 9, 18, 19, 20, 20]\n",
    "np.mean(sample)\n",
    "\n",
    "b) 86.9275\n",
    "\n",
    "import numpy as np\n",
    "sample = [10, 25, 12, 35, 14, 18, 16, 15, 22, 10, 9, 11, 49, 20, 15, 9, 18, 19, 20, 20]\n",
    "np.var(sample)import scipy.stats as stats\n",
    "binom = stats.binom(n=10, p=0.6)\n",
    "1 - binom.pmf(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pandas_query(df):\n",
    "    '''Returns a DataFrame containing the average size of each university\n",
    "    type ordered by average size in ascending order.\n",
    "\n",
    "    Function assumes the input DataFrame contains these columns:\n",
    "        name, address, Website, Type, Size\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: Pandas DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame\n",
    "    '''\n",
    "    grouped = df.groupby(['name', 'address', 'Website', 'Type']).mean().reset_index()\n",
    "    grouped.sort_values('Size', ascending=False)\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment 2 Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import itertools \n",
    "import numpy as np\n",
    "def roll_the_dice(n_simulations = 1000):\n",
    "    '''Two unbiased, six sided, dice are thrown one time and the sum of the\n",
    "    faces is observed (so if you rolled a 3 and a 1, the sum is 4). A\n",
    "    simulation estimates probability that the total score is an even number\n",
    "    or a number greater than 7.  This is an estimated probability, based on\n",
    "    rolling the two dice n_simulations times.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_simulations: float\n",
    "        Number of rolls of the dice\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    '''\n",
    "    die_possibilities = [1,2,3,4,5,6]\n",
    "    two_die_possibilities = list(itertools.product(die_possibilities, die_possibilities))\n",
    "#     print(two_die_possibilities)\n",
    "#     print(len(two_die_possibilities))\n",
    "    two_die_poss_array = np.array(two_die_possibilities)\n",
    "#     print(two_die_poss_array)\n",
    "    two_die_sums_array = np.sum(two_die_poss_array, axis=1)\n",
    "#     print(two_die_sums_array)\n",
    "    two_die_sums_meet_crit = (two_die_sums_array % 2 == 0) | (two_die_sums_array > 7)\n",
    "#     print(two_die_sums_meet_crit)\n",
    "    expected = np.sum(two_die_sums_meet_crit.astype(int)) / len(two_die_poss_array)\n",
    "#     print(np.sum(two_die_sums_meet_crit.astype(int)))\n",
    "#     print(len(two_die_poss_array))\n",
    "#     print(expected)\n",
    "    return expected\n",
    "\n",
    "roll_the_dice(n_simulations = 1000) # 0.6666666666666666 is correct, passes test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. A coin is biased at 0.6 in favor of heads. What is the probability of flipping 8 or more heads in 10 flips of this coin?\n",
    "*My Original Answer (2/3pts):*\n",
    "```\n",
    "P(X >= 8) = 0.785\n",
    "How:\n",
    "P(X >= 8) = 1 - P(X < 8)\n",
    "Need binom(n=10, p=0.6)\n",
    "Code:\n",
    "```\n",
    "```python\n",
    "import scipy.stats as stats\n",
    "binom = stats.binom(n=10, p=0.6)\n",
    "1 - binom.pmf(7)\n",
    "```\n",
    "\n",
    "**REVISED Answer:**\n",
    "```\n",
    "P(X >= 8) = 0.167\n",
    "How:\n",
    "P(X >= 8) = (1 - P(X <= 8)) + P(X = 8)\n",
    "Need binom(n=10, p=0.6)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16728975359999995"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "binom = stats.binom(n=10, p=0.6)\n",
    "(1 - binom.cdf(8)) + binom.pmf(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. You've found a secret admirer note on your desk, and don't know who it might've come from but you know it must've been one of your colleagues: Jack, John, or Jimmy.\n",
    "\n",
    "* As of yesterday, you thought it was twice as likely that Jimmy had a crush on you than John, and that John and Jack were equally likely to have a crush on you.\n",
    "* However even if Jimmy liked you, you think there'd only be a 5% chance he'd leave you a note.\n",
    "* On the other hand, if Jack liked you there'd be a whopping 50% chance he'd leave you a note.\n",
    "* If John liked you, there'd be a 20% chance he'd leave you a note.\n",
    "\n",
    "What's the probability that the note came from John?\n",
    "\n",
    "*My Original Answer (1/3pts):*\n",
    "```\n",
    "P(Jimmy crush) = 2*P(John crush)\n",
    "P(John crush) = P(Jack crush) = 1/3\n",
    "P(Jimmy crush) = 2/3\n",
    "\n",
    "P(Jimmy note) |  P(Jimmy crush) = 0.05\n",
    "P(Jack note) |  P(Jack crush) = 0.5\n",
    "P(John note) |  P(John crush) = 0.2\n",
    "\n",
    "P(John note) = (P(John note) |  P(John crush) ) * P(John crush) = 0.2*1/3 = 0.0667\n",
    "```\n",
    "\n",
    "**Figure out answer for 3/3pts**\n",
    "\n",
    "ACTUAL Answer:\n",
    "```\n",
    "`J1 = {Jack likes you}, J2 = {John likes you}, J3 = {Jimmy likes you}`\n",
    "\n",
    "Calculate their probabilities.\n",
    "\n",
    "`P(J1) = P(J2), P(J3) = 2 * P(J1), P(J1) + P(J2) + P(J3) = 1`\n",
    "\n",
    "`implies P(J1) = P(J2) = 0.25, P(J3) = 0.50`\n",
    "\n",
    "`N = {Note is left}`\n",
    "\n",
    "Find probability of ever getting a note\n",
    "\n",
    "`P(N|J1) = 0.50, P(N|J2) = 0.20, P(N|J3) = 0.05.`\n",
    "\n",
    "`P(N) = P(N|J1) * P(J1) + P(N|J2) * P(J2) + P(N|J3) * P(J3)`\n",
    "\n",
    "     = 0.50 * 0.25 + 0.20 * 0.25 + 0.05 * 0.50\n",
    "     \n",
    "     = 0.20\n",
    "\n",
    "Use Bayes' theorem\n",
    "\n",
    "`P(J2|N) = P(N|J2) * P(J2) / P(N) `\n",
    "        `= (0.20 * .25) / 0.20 = 0.25`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. The total number of log-ins to a website for 20 different randomly selected users from 2018 are listed below (which you can treat as a sample from the population of all users of the website in 2018):\n",
    "\n",
    "[10, 25, 12, 35, 14, 18, 16, 15, 22, 10, 9, 11, 49, 20, 15, 9, 18, 19, 20, 20]\n",
    "\n",
    "a) What is the sample mean?\n",
    "\n",
    "b) What is the sample variance?\n",
    "\n",
    "*My Original Answer (2/3pts):*\n",
    "```\n",
    "a) 18.35\n",
    "\n",
    "import numpy as np\n",
    "sample = [10, 25, 12, 35, 14, 18, 16, 15, 22, 10, 9, 11, 49, 20, 15, 9, 18, 19, 20, 20]\n",
    "np.mean(sample)\n",
    "\n",
    "b) 86.9275\n",
    "\n",
    "import numpy as np\n",
    "sample = [10, 25, 12, 35, 14, 18, 16, 15, 22, 10, 9, 11, 49, 20, 15, 9, 18, 19, 20, 20]\n",
    "np.var(sample)\n",
    "```\n",
    " \n",
    "\n",
    "**TODO: Find out answer for 3/3pts**\n",
    "\n",
    "ACTUAL Answer:\n",
    "```\n",
    "b) 91.50263157894737\n",
    "import numpy as np\n",
    "v = [10, 25, 12, 35, 14, 18, 16, 15, 22, 10, 9, 11, 49, 20, 15, 9, 18, 19, 20, 20]\n",
    "np.var(v) * len(v) / (len(v) - 1) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var: 86.92750000000002\n",
      "86.9275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.50263157894737"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = [10, 25, 12, 35, 14, 18, 16, 15, 22, 10, 9, 11, 49, 20, 15, 9, 18, 19, 20, 20]\n",
    "import numpy as np\n",
    "mean = np.mean(sample)\n",
    "\n",
    "var = sum([(x - mean)**2 for x in sample]) / len(sample)\n",
    "print('var:', var)\n",
    "print(np.var(sample))\n",
    "\n",
    "import numpy as np\n",
    "v = [10, 25, 12, 35, 14, 18, 16, 15, 22, 10, 9, 11, 49, 20, 15, 9, 18, 19, 20, 20]\n",
    "np.var(v) * len(v) / (len(v) - 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
